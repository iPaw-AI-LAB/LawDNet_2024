# LawDNet 2024



### BUG

- [ ] å¤„ç†æ•°æ®é›†çš„æ—¶å€™ï¼ŒJinpeng æ•°æ®é›†çš„ crop face çš„é•¿åº¦å’Œ DeepSpeech é•¿åº¦ä¸ä¸€è‡´
- [ ] éŸ³é¢‘çš„ DeepSpeech å¸§æ•°æ€»æ¯”è§†é¢‘å¸§å¤š 3 å¸§
- [ ] å¯¹ loss çš„æƒé‡æ•æ„Ÿï¼Œå°¤å…¶æ˜¯ syncnet_lossï¼Œå¯¼è‡´éœ‡è¡ä¸¥é‡ï¼Œä½†æ˜¯ä¸å½±å“è®­ç»ƒç»“æœ
- [ ] äººå¤´å ç”»é¢å…¨éƒ¨æ—¶æœ‰ç½‘æ ¼ç°è±¡ï¼Œå¯èƒ½æ˜¯ affine grid çš„ align corneræçš„é¬¼ï¼Œæœ‰å¾…å®éªŒè§£å†³
- [ ] DP2 ç‰ˆæœ¬çš„cuda åªèƒ½ä½¿ç”¨0å·ï¼Œå¾…æ”¹è¿›

### æ”¹è¿›

- [x] æ ¹æ®éŸ³é¢‘çš„é•¿åº¦æ¥ç¡®å®šæ‹†å¸§çš„æ•°é‡ï¼Œæ¨ç†æ—¶
- [ ] ç”¨ DeepSpeech PyTorch æ¥åšæ•°æ®é›†
- [ ] ç”¨hubertæ¥æå–éŸ³é¢‘ç‰¹å¾ï¼Œä»¥é€‚åº”ä¸­æ–‡åœºæ™¯
- [ ] è®­ç»ƒæ•°æ®å¾ˆé‡è¦ï¼Œç›®å‰HDTFè®­ç»ƒæ•ˆæœä¿è¯ç¨³å®šï¼Œå…¶å®ƒæ•°æ®é›†ä¸ä¸€å®šï¼Œåº”è¯¥æ˜¯deepspeechéŸ³é¢‘ç‰¹å¾ä¸é€‚åº”ä¸­æ–‡


## ç¯å¢ƒé…ç½®
å…ˆå®‰è£…tensorflow_gpu = 1.15, æ¨¡å‹whlåœ¨[ç™¾åº¦ç½‘ç›˜](https://pan.baidu.com/s/1bNJT409wNlcJgkiAGHcONA?pwd=ipaw)ï¼Œ æå–ç ï¼šipaw 

ä¸‹è½½å®Œæˆåï¼Œå­˜æ”¾äº`./tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl`

**å…ˆå®‰è£…tensorflow, å†å®‰è£…torch**

```bash
conda create --name LawDNet python=3.9
conda activate LawDNet
pip install tensorflow_gpu-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl
conda install -c conda-forge ffmpeg
pip install -r requirements.txt
```

- éœ€è¦ç”¨åˆ°çš„æ¨¡å‹: æ¢è„¸ ï¼Œdeepspeech(tensorflow), vgg ç­‰ã€‚ [ç™¾åº¦ç½‘ç›˜](https://pan.baidu.com/s/1bNJT409wNlcJgkiAGHcONA?pwd=ipaw)ï¼Œ æå–ç ï¼šipaw 

- output_graph.pb : pretrained deepspeech model of tensorflow 1.15ï¼Œç”¨äºæå–éŸ³é¢‘ç‰¹å¾ï¼Œæ”¾åœ¨```./asserts/```
- syncnet_256mouth.pth: ç”¨äºè®­ç»ƒæ—¶è®¡ç®—å”‡å½¢åŒæ­¥æŸå¤±ï¼Œæ”¾åœ¨```./asserts/```

---

#### æœ‰ç”¨çš„å°å·¥å…·ï¼š `./æœ‰ç”¨çš„è„šæœ¬å°å·¥å…·/`
1. å‹ç¼©æ–‡ä»¶å¹¶æ˜¾ç¤ºè¿›åº¦ `sh ./å‹ç¼©æ–‡ä»¶.sh` 
2. åˆå¹¶ä¸åŒæ•°æ®é›†çš„landmarkå­—å…¸ `é‚“-å¤„ç†å¤§æ•°æ®é›†.ipynb`
3. åˆå¹¶ä¸¤ç»„æ•°æ®é›†`sh ./ç§»åŠ¨æ•°æ®é›†.sh`ï¼Œæ–°å¤„ç†çš„æ•°æ®é›†å’Œè€æ•°æ®é›†åˆå¹¶æ—¶ç”¨åˆ°

---
# æ•°æ®é›†ç­›é€‰ï¼Œå¯¹é½ï¼Œæå–landmark
ç”¨**[æ•°æ®é›†ç­›é€‰ï¼Œå¯¹é½ï¼Œæå–landmark](https://github.com/iPaw-AI-LAB/syncnet)ä»£ç **å¤„ç†è§†é¢‘ 
- åŸºäº [syncnet-python](https://github.com/joonson/syncnet_python) é‡æ„

**åŠŸèƒ½ï¼š** å°†è§†é¢‘è½¬ä¸º25fpsï¼Œå¹¶æ£€æµ‹å¾—åˆ° `landmark.csv` æ–‡ä»¶ã€‚è‹¥åŸè§†é¢‘å³ä¸º25fpsï¼Œä¿å­˜åœ¨æºæ–‡ä»¶å¤¹ (`root_folder`)ï¼›è‹¥åŸè§†é¢‘ä¸ä¸º25fpsï¼Œå­˜æ”¾åœ¨ç›®æ ‡æ–‡ä»¶å¤¹ (`output_folder`)ã€‚

**æœ€ä½³å®è·µï¼š**
- é€šå¸¸å°† `root_folder` æºæ–‡ä»¶å¤¹å’Œ `output_folder` ç›®æ ‡æ–‡ä»¶å¤¹è®¾ç½®ä¸ºç›¸åŒçš„æ–‡ä»¶å¤¹ã€‚å¤„ç†å®Œä¹‹åï¼Œå°†è§†é¢‘ç§»åŠ¨åˆ° `training_data` æ–‡ä»¶å¤¹ã€‚
- ä½¿ç”¨ `./syncnet/move_dataset.ipynb` å¯ä»¥åªç§»åŠ¨åŒæ—¶å­˜åœ¨ `.mp4` å’Œ `.csv` æ–‡ä»¶çš„æ•°æ®ï¼Œä»è€Œèµ·åˆ°è¿‡æ»¤çš„ä½œç”¨ã€‚

## è®­ç»ƒæ•°æ®é›†å‡†å¤‡
å°†éŸ³è§†é¢‘å¯¹é½çš„æ•°æ®é›†è¿›è¡Œé¢„å¤„ç†ï¼Œå¹¶æ­£è„¸åŒ–ã€‚

#### æ•°æ®å¤„ç†è„šæœ¬


- å°†è§†é¢‘ç§»åŠ¨åˆ°æœ¬å®éªŒçš„ `./assert/training_data/split_video_25fps`
- å°†è§†é¢‘å¯¹åº”çš„csvç§»åŠ¨åˆ°æœ¬å®éªŒä»£ç çš„`./assert/training_data/split_video_25fps_landmark_openface`
   - ç§»åŠ¨è§†é¢‘å’Œå¯¹åº”csvçš„ä»£ç å¯ä»¥ç”¨`./syncnet/move_dataset.ipynb`, ä»…ç§»åŠ¨è§†é¢‘å’ŒcsvåŒæ—¶å­˜åœ¨çš„æ•°æ®
- è¿è¡Œ`data_processing_æ­£è„¸åŒ–.py`, è¿›è¡Œè®­ç»ƒæ•°æ®é›†å‡†å¤‡
    - cropåçš„å›¾åƒå¤§å°ç»Ÿä¸€ä¸º **416 320**ï¼Œæ¯”ä¾‹ä¸º1.3:1ï¼Œé€šè¿‡`FaceAlign`ç±»çš„å‚æ•°`out_W`è¿›è¡Œè®¾ç½®
      - å¾—åˆ°æ­£è„¸åŒ–çš„crop landmark å­—å…¸ `./asserts/training_data/landmark_crop_dic.npy`
      - è‹¥éœ€è¦åˆå¹¶ä¸åŒæ•°æ®é›†çš„landmarkå­—å…¸`landmark_crop_dic.npy`,å¯è¿è¡Œ`./æœ‰ç”¨çš„è„šæœ¬å°å·¥å…·/é‚“-å¤„ç†å¤§æ•°æ®é›†.ipynb`
      - é‡æ–°ç”Ÿæˆå®Œæ•´çš„jsonæ–‡ä»¶ `python data_processing_æ­£è„¸åŒ–.py --generate_training_json` 

- è®­ç»ƒæ•°æ®é›†å­˜æ”¾äº`./training_data`



### ä¸€å¥å‘½ä»¤å¤„ç†è®­ç»ƒæ•°æ®
```sh
python data_processing_æ­£è„¸åŒ–.py --extract_video_frame_multithreading && \
python data_processing_æ­£è„¸åŒ–.py --extract_audio && \
python data_processing_æ­£è„¸åŒ–.py --extract_deep_speech_multithreading && \
python data_processing_æ­£è„¸åŒ–.py --crop_face_multithreading && \
python data_processing_æ­£è„¸åŒ–.py --generate_training_json
```

### å¤„ç†è®­ç»ƒæ•°æ®æ­¥éª¤

- `--extract_video_frame`ï¼šå¯ç”¨ä»æºè§†é¢‘ä¸­æå–è§†é¢‘å¸§ã€‚:
  ```sh
  python data_processing_æ­£è„¸åŒ–.py --extract_video_frame
  ```
  - `--extract_video_frame_multithreading`ï¼šå¯ç”¨å¤šçº¿ç¨‹æå–è§†é¢‘å¸§ï¼Œä»¥æé«˜æ•ˆç‡ã€‚:
    ```sh
    python data_processing_æ­£è„¸åŒ–.py --extract_video_frame_multithreading
    ```

- `--extract_audio`ï¼šå¯ç”¨ä»æºè§†é¢‘ä¸­æå–éŸ³é¢‘ã€‚
  ```sh
  python data_processing_æ­£è„¸åŒ–.py --extract_audio
  ```

- `--extract_deep_speech`ï¼šå¯ç”¨ä»éŸ³é¢‘æ–‡ä»¶ä¸­æå–DeepSpeechç‰¹å¾ã€‚
  ```sh
  python data_processing_æ­£è„¸åŒ–.py --extract_deep_speech
  ```

- `--crop_face`ï¼šå¯ç”¨æ ¹æ®landmarkè£å‰ªäººè„¸ã€‚:
  ```sh
  python data_processing_æ­£è„¸åŒ–.py --crop_face
  ```
  - `--crop_face_multithreading`ï¼šå¯ç”¨å¤šçº¿ç¨‹è£å‰ªäººè„¸ï¼Œä»¥æé«˜æ•ˆç‡ã€‚:
    ```sh
    python data_processing_æ­£è„¸åŒ–.py --crop_face_multithreading
    ```

- `--generate_training_json`ï¼šå¯ç”¨ç”Ÿæˆè®­ç»ƒJSONæ–‡ä»¶ã€‚
  ```sh
  python data_processing_æ­£è„¸åŒ–.py --generate_training_json
  ```


# ä»£ç ä½¿ç”¨è¯´æ˜

## è®­ç»ƒ 
é‡‡ç”¨ coarse to fine çš„è®­ç»ƒç­–ç•¥ï¼Œæ¯ä¸ªé˜¶æ®µæœ‰è‡ªå·±çš„configæ–‡ä»¶ï¼Œä½äº```./config/experiment ``` 

åŸºç¡€é…ç½®æ–‡ä»¶æ˜¯```./config/config.py```

### DDP å¹¶è¡Œè®­ç»ƒæ–¹å¼ - å¿«
æ‰“å¼€```train_sequence_distributed.sh``` ä¿®æ”¹NAME(å®éªŒåç§°)
ç›´æ¥æ‰§è¡Œè„šæœ¬ï¼š```sh train_sequence_distributed.sh```
```python
sh train_sequence_distributed.sh
# å¯¹åº”å‚æ•°åœ¨config.py å’Œ train_sequence_distributed.sh ä¸­ä¿®æ”¹
```


| è®­ç»ƒé…ç½®é¡¹åç§°               | æè¿°                                                         | ç¤ºä¾‹å€¼                   |
|--------------------------|--------------------------------------------------------------|--------------------------|
| `augment_num`            | æ•°æ®å¢å¼ºçš„æ¬¡æ•°ã€‚                                               | `3`                      |
| `mouth_region_size`      | å˜´éƒ¨åŒºåŸŸçš„å¤§å°ã€‚                                              | `288`ï¼ˆæˆ–`256`ï¼‰        |
| `batch_size`             | è®­ç»ƒæ—¶æ¯ä¸ªæ‰¹æ¬¡çš„æ ·æœ¬æ•°é‡ã€‚                                   | `8`                      |
| `pretrained_frame_DINet_path` | ä¸Šä¸€è½®coarseè®­ç»ƒçš„æ¨¡å‹è·¯å¾„ã€‚                               | `./output/..._epoch_119.pth` |
| `result_path`            | ç»“æœå’Œæ¨¡å‹ä¿å­˜çš„è·¯å¾„ã€‚                                       | `./output/.../clip_training_256` |
| `pretrained_syncnet_path`| SyncNetæ¨¡å‹çš„é¢„è®­ç»ƒè·¯å¾„ã€‚                                    | `./asserts/syncnet_256mouth.pth` |
| `non_decay`              | å­¦ä¹ ç‡å¼€å§‹è¡°å‡ä¹‹å‰çš„epochæ•°é‡ã€‚                                    | `300`                    |
| `decay`                  | å­¦ä¹ ç‡è¡°å‡çš„çš„epochæ•°é‡ã€‚                                           | `300`                    |
| `start_epoch`            | è®­ç»ƒå¼€å§‹çš„epochï¼Œç”¨äºæ–­ç‚¹ç»­ç»ƒæˆ–ä»é›¶å¼€å§‹è®­ç»ƒã€‚             | `1`                      |
| `resume`                 | æ˜¯å¦ä»æ–­ç‚¹æ¢å¤è®­ç»ƒã€‚                                          | `False` æˆ– `True`       |


å¦‚æœæ‚¨çš„æ­¤è½®è®­ç»ƒä¸­æ–­äº†ï¼Œå¸Œæœ›ä»ä¹‹å‰çš„è®­ç»ƒæ–­ç‚¹ç»§ç»­è®­ç»ƒï¼Œæ‚¨å¯ä»¥è®¾ç½®å¦‚ä¸‹ï¼š

```python
{
    'resume': True,
    'start_epoch': æ–­ç‚¹è®­ç»ƒçš„epoch
}
```

- æ¨¡å‹ä¿å­˜ä½ç½®ï¼š ```./output/training_model_weight/NAME(å®éªŒåç§°)```


### DPå¹¶è¡Œæ–¹å¼è®­ç»ƒ-æ…¢
ç›´æ¥æ‰§è¡Œè„šæœ¬ï¼š```sh ./train_sequence.sh```

### [wandb æŸ¥çœ‹è®­ç»ƒæ—¥å¿—](https://wandb.ai/ai-zhua)

### è®­ç»ƒå®¹æ˜“å‡ºé”™çš„åœ°æ–¹
1. è¯·ä»”ç»†æ£€æŸ¥å„ä¸ªè®­ç»ƒé˜¶æ®µçš„configæ–‡ä»¶
2. åŠ¡å¿…ä¿è¯coarse to fine è®­ç»ƒï¼Œç›´æ¥è®­ç¬¬å››æ­¥å¾—åˆ°çš„å˜´éƒ¨æ˜¯æ¨¡ç³Šçš„ï¼Œæ¨¡å‹æ²¡æœ‰åŠæ³•ä¸€æ­¥ç™»å¤©
3. è¯·æ£€æŸ¥torchrunçš„ç«¯å£å·æ˜¯å¦è¢«å ç”¨
4. è‹¥è®­ç»ƒæ•ˆæœå˜´å·´æ¨¡ç³Šï¼Œåˆ™å¢åŠ æœ€åä¸€æ­¥çš„epochåˆ°200ä»¥ä¸Š
5. decay epoch å’Œ non decay epoch æ•°é‡å¿…é¡»ç›¸åŒï¼Œå¦åˆ™ä¼šå¯¼è‡´å­¦ä¹ ç‡ä¸ºè´Ÿæ•°
6. è®­ç»ƒæ•°æ®å¾ˆé‡è¦ï¼Œæ•°æ®é›†è¶Šé«˜æ¸…ï¼ŒéŸ³é¢‘æ— æ‚éŸ³æœ€å¥½ã€‚ç›®å‰HDTFè®­ç»ƒæ•ˆæœä¿è¯ç¨³å®šï¼Œå…¶å®ƒæ•°æ®é›†ä¸ä¸€å®šï¼Œåº”è¯¥æ˜¯deepspeechéŸ³é¢‘ç‰¹å¾ä¸é€‚åº”ä¸­æ–‡ï¼Œä¸è¦ç›²ç›®å¢åŠ ä¸­æ–‡æ•°æ®é›†ï¼Œä¸å¥½çš„æ•°æ®é›†ç”šè‡³æœ‰ğŸ˜¡åæ•ˆæœ
7. æœ¬é¡¹ç›®å–æ¶ˆäº†BatchNormå±‚ï¼Œè®­ç»ƒæ—¶è¯·æŠŠbatchsizeè°ƒå°ï¼Œæœ¬å®éªŒè®¾ä¸º1
8. ä½¿ç”¨deepspeech2 pytorchè®­ç»ƒæ—¶ï¼Œæ³¨æ„deepspeech2 pytorchæ— æ³•å¤„ç†é™éŸ³æ•°æ®ï¼Œé‡åˆ°é™éŸ³è§†é¢‘è¯·æ‰‹åŠ¨åˆ é™¤
   1. [deepspeech pytorch 2](https://github.com/iPaw-AI-LAB/deepspeech_pytorch)
   2. æå–æ²¡æœ‰ç»è¿‡softmaxçš„deepspeechç‰¹å¾: `python extract_deepspeech_pytorch2.py`


## æµ‹è¯•ï¼š

ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ï¼Œæµ‹è¯•è§†é¢‘ï¼š[ç™¾åº¦ç½‘ç›˜](https://pan.baidu.com/s/1FFINqyyz2to96_-A7QhhHA?pwd=ipaw) æå–ç : ipaw 

ä¿®æ”¹``` inference_function.py ``` é‡Œé¢çš„å‚æ•°ï¼š

- **video_path**: è¾“å…¥è§†é¢‘æ–‡ä»¶çš„è·¯å¾„ã€‚
- **audio_path**: è¾“å…¥éŸ³é¢‘æ–‡ä»¶çš„è·¯å¾„ã€‚
- **deepspeech_model_path**: DeepSpeech æ¨¡å‹æ–‡ä»¶çš„è·¯å¾„ï¼ˆ`output_graph.pb`ï¼‰ã€‚
- **lawdnet_model_path**: é¢„è®­ç»ƒ LawDNet æ¨¡å‹æ–‡ä»¶çš„è·¯å¾„ï¼ˆ`checkpoint_epoch_120.pth`ï¼‰ã€‚
- **output_dir**: ä¿å­˜è¾“å‡ºè§†é¢‘çš„ç›®å½•ã€‚
- **BatchSize**: å¤„ç†è§†é¢‘å¸§çš„æ‰¹å¤„ç†å¤§å°ã€‚
- **mouthsize**: å¤„ç†çš„å˜´éƒ¨åŒºåŸŸå¤§å°ï¼ˆä¾‹å¦‚ `288`ï¼‰ã€‚
- **gpu_index**: ä½¿ç”¨çš„GPUç´¢å¼•ï¼ˆè®¾ç½®ä¸º `-1` è¡¨ç¤ºä½¿ç”¨CPUï¼‰ã€‚
- **output_name**: è¾“å‡ºè§†é¢‘æ–‡ä»¶çš„è‡ªå®šä¹‰åç§°ã€‚

``` sh
cd ./Exp-of-Junli/ 
python inference_function.py
```

```./Exp-of-Junli/optimized-prediction-deng.ipynb # æ–¹ä¾¿å•æ­¥è°ƒè¯•çœ‹ä¸­é—´ç»“æœ```

```./Exp-of-Junli/inference_function.py # ä¿®æ”¹æ¨¡å‹è·¯å¾„ï¼Œæ•°å­—äººè§†é¢‘ï¼ŒéŸ³é¢‘```

```./Exp-of-Junli/server_LawDNet.py # æä¾›serveræœåŠ¡```

## serveræœåŠ¡
ç”Ÿæˆè§†é¢‘å¹¶å‘é€åˆ°æŒ‡å®šç«¯å£

ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ï¼Œæµ‹è¯•è§†é¢‘ï¼š[ç™¾åº¦ç½‘ç›˜](https://pan.baidu.com/s/1FFINqyyz2to96_-A7QhhHA?pwd=ipaw) æå–ç : ipaw 

```sh
cd Exp-of-Junli;
python server_LawDNet.py
```

## å‚æ•°åˆ—è¡¨

| å‚æ•°åç§°               | æè¿°                                                         | é»˜è®¤å€¼                   |
|------------------------|--------------------------------------------------------------|--------------------------|
| `video_path`          | æ¨¡ç‰ˆè§†é¢‘æ–‡ä»¶çš„è·¯å¾„ã€‚                                           | `./template/...mp4`     |
| `audio_path`          | è¾“å…¥éŸ³é¢‘æ–‡ä»¶çš„è·¯å¾„ã€‚ï¼ˆç”±chatttsæä¾›ï¼‰                            | `./template/...wav`     |
| `output_dir`          | è¾“å‡ºè§†é¢‘æ–‡ä»¶çš„ç›®å½•ã€‚                                           | `./output_video`        |
| `deepspeech_model_path`| DeepSpeech æ¨¡å‹æ–‡ä»¶çš„è·¯å¾„ã€‚                                    | `../asserts/output_graph.pb` |
| `lawdnet_model_path`  | LawdNet æ¨¡å‹æ–‡ä»¶çš„è·¯å¾„ã€‚                                       | `../output/...pth`      |
| `BatchSize`           | å¤„ç†æ‰¹æ¬¡å¤§å°ã€‚                                                | `20`                     |
| `mouthsize`           | å˜´éƒ¨æ¨¡å‹çš„å¤§å°ã€‚                                              | `288`                    |
| `gpu_index`           | ä½¿ç”¨çš„GPUç´¢å¼•å·ã€‚                                             | `1`                      |
| `result_video_path`   | ç”Ÿæˆè§†é¢‘æ–‡ä»¶çš„å®Œæ•´è·¯å¾„ï¼Œç”±å‡½æ•°ç”Ÿæˆå¹¶è¿”å›ã€‚                | ï¼ˆç”±å‡½æ•°ç”Ÿæˆï¼‰           |

## ä½¿ç”¨æ–¹æ³•

1. ç¡®ä¿æ‰€æœ‰å¿…è¦çš„æ–‡ä»¶è·¯å¾„æ­£ç¡®æ— è¯¯ã€‚
2. æ ¹æ®éœ€è¦è°ƒæ•´æ‰¹æ¬¡å¤§å°ã€å˜´éƒ¨æ¨¡å‹å¤§å°å’ŒGPUç´¢å¼•ã€‚
3. è¿è¡Œè„šæœ¬ï¼Œå®ƒå°†è‡ªåŠ¨å¤„ç†è§†é¢‘å’ŒéŸ³é¢‘ï¼Œå¹¶ç”Ÿæˆè¾“å‡ºæ–‡ä»¶ã€‚

## èµ„æº

[å¸¸ç”¨çš„è®­ç»ƒå‘½ä»¤/æµ‹è¯•å‘½ä»¤](https://docs.qq.com/doc/DTENSWFlpTVFvSkhn) - è…¾è®¯æ–‡æ¡£

[å®éªŒè®°å½•å’Œdemo](https://y5ucgsxnni.feishu.cn/docx/QSxadxHp0o6bgLxiiEbc0nvNnZd) - é£ä¹¦äº‘æ–‡æ¡£

[è®ºæ–‡åœ°å€ï¼ˆéœ€å®¡æ‰¹ï¼‰](https://www.overleaf.com/read/vkhhnxrvwbdw#3778eb) - Overleaf

[LawDNetä¸»é¡µ](https://cucdengjunli.github.io/idf/) - å®£ä¼ ç½‘é¡µ

[æ•°æ®é›†è¯„æµ‹æŒ‡æ ‡ä»£ç ](https://gitee.com/dengjunli/evaluation_wav2lip) - è¯„ä»·æŒ‡æ ‡

[å‚è€ƒè®ºæ–‡](https://fuxivirtualhuman.github.io/pdf/AAAI2023_FaceDubbing.pdf) - èµ„æº

[å°†å…¶å·¥ç¨‹åŒ–çš„è®°å½•](https://kdocs.cn/l/cinrYOJIsclj) - å·¥ç¨‹åŒ–æ–‡æ¡£

[codebase-DINet](https://github.com/MRzzm/DINet) - é¸£è°¢









