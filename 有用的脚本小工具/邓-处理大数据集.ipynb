{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e788b2b-5db7-4c37-9784-83a61191b305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# 加载保存为.npy的两个字典\n",
    "dict1 = np.load('./training_data/landmark_crop_dic-只有后300中文数据.npy', allow_pickle=True).item()\n",
    "dict2 = np.load('./training_data-中英文大数据集/landmark_crop_dic-无后300中文数据.npy', allow_pickle=True).item()\n",
    "\n",
    "# 合并两个字典\n",
    "combined_dict = {**dict1, **dict2}\n",
    "\n",
    "# 将合并后的字典保存为.npy文件\n",
    "np.save('./training_data-中英文大数据集/landmark_crop_dic.npy', combined_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9a7176",
   "metadata": {},
   "source": [
    "### 检查处理后的视频对是否正确\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e59b10e9-80ed-4d15-95aa-66a85e273238",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './landmark_crop_dic-并加上金鹏老师.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# 加载.npy文件\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m loaded_dict \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39m./landmark_crop_dic-并加上金鹏老师.npy\u001b[39;49m\u001b[39m'\u001b[39;49m, allow_pickle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mitem()\n\u001b[1;32m      4\u001b[0m \u001b[39m# 获取第一个键值对\u001b[39;00m\n\u001b[1;32m      5\u001b[0m first_key, first_value \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(loaded_dict\u001b[39m.\u001b[39mitems()))\n",
      "File \u001b[0;32m~/miniconda3/envs/DJL_codeformer/lib/python3.8/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './landmark_crop_dic-并加上金鹏老师.npy'"
     ]
    }
   ],
   "source": [
    "# 加载.npy文件\n",
    "loaded_dict = np.load('./landmark_crop_dic-并加上金鹏老师.npy', allow_pickle=True).item()\n",
    "\n",
    "# 获取第一个键值对\n",
    "first_key, first_value = next(iter(loaded_dict.items()))\n",
    "\n",
    "# 打印第一个键值对\n",
    "print(f\"第一个键: {first_key}\")\n",
    "print(f\"第一个值: {first_value}\")\n",
    "\n",
    "\n",
    "# 获取第一个键值对\n",
    "first_key, first_value = next(iter(dict1.items()))\n",
    "\n",
    "# 打印第一个键值对\n",
    "print(f\"第一个键: {first_key}\")\n",
    "print(f\"第一个值: {first_value}\")\n",
    "\n",
    "\n",
    "# 获取第一个键值对\n",
    "first_key, first_value = next(iter(dict2.items()))\n",
    "\n",
    "# 打印第一个键值对\n",
    "print(f\"第一个键: {first_key}\")\n",
    "print(f\"第一个值: {first_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6181f2",
   "metadata": {},
   "source": [
    "# 移动数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c02186",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sh 移动数据集.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0de647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./training_data_金鹏高清棚拍数据集汇总"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38000b53",
   "metadata": {},
   "source": [
    "## 创建training_data文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d372ee4-08a6-4fde-957c-283fc06edf43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "创建 ./training_data_金鹏高清棚拍数据集汇总/split_video_25fps\n",
      "创建 ./training_data_金鹏高清棚拍数据集汇总/split_video_25fps_audio\n",
      "创建 ./training_data_金鹏高清棚拍数据集汇总/split_video_25fps_crop_face\n",
      "创建 ./training_data_金鹏高清棚拍数据集汇总/split_video_25fps_deepspeech\n",
      "创建 ./training_data_金鹏高清棚拍数据集汇总/split_video_25fps_landmark_openface\n",
      "创建 ./training_data_金鹏高清棚拍数据集汇总/split_video_25fps_frame\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "training_data_folder = './training_data_金鹏高清棚拍数据集汇总'\n",
    "subfolders = ['split_video_25fps', 'split_video_25fps_audio', 'split_video_25fps_crop_face', 'split_video_25fps_deepspeech', 'split_video_25fps_landmark_openface', 'split_video_25fps_frame']\n",
    "\n",
    "if not os.path.exists(training_data_folder):\n",
    "    os.makedirs(training_data_folder)\n",
    "    for subfolder in subfolders:\n",
    "        os.makedirs(os.path.join(training_data_folder, subfolder))\n",
    "        print(\"创建\",os.path.join(training_data_folder, subfolder))\n",
    "        \n",
    "else:\n",
    "    print(\"已存在\",training_data_folder)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175777b3",
   "metadata": {},
   "source": [
    "# 创建train——weight 文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5e398a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "training_model_weight = './training_model_weight'\n",
    "subfolders = ['clip_training_256', 'frame_training_64', 'frame_training_128', 'frame_training_256']\n",
    "\n",
    "if not os.path.exists(training_model_weight):\n",
    "    os.makedirs(training_model_weight)\n",
    "    for subfolder in subfolders:\n",
    "        os.makedirs(os.path.join(training_model_weight, subfolder))\n",
    "        print(\"创建\",os.path.join(training_model_weight, subfolder))\n",
    "        \n",
    "else:\n",
    "    print(\"已存在\",training_model_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a28591d9-9160-469b-be16-3fc0dccbabd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp /root/autodl-tmp/金鹏模特视频/京东副总裁/7坐说话美颜.* ./training_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc4a8829-981b-468f-9fd9-2020c820b212",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files in /root/autodl-tmp/DINet-gitee/DINet-update/asserts/training_data/split_video_25fps: 1\n"
     ]
    }
   ],
   "source": [
    "## 查看文件夹内文件总数\n",
    "\n",
    "import os\n",
    "\n",
    "folder_path = '/root/autodl-tmp/DINet-gitee/DINet-update/asserts/training_data/split_video_25fps'\n",
    "num_files = len(os.listdir(folder_path))\n",
    "\n",
    "print(f'Total number of files in {folder_path}: {num_files}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
